{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQIonGAJBYMF"
      },
      "source": [
        "# Deep Learning Satellite Image Classification Pipeline\n",
        "\n",
        "**Project Steps:**\n",
        "1. Data Loading & Preprocessing (Resize to 224x224)\n",
        "2. Train 3 DenseNet Models (121, 169, 201)\n",
        "3. Select Top 2 Best Performing Models\n",
        "4. Feature Extraction & Fusion (Dimension Reduction)\n",
        "5. Train Classical Classifiers (RF, DT, Softmax) on Fused Features\n",
        "6. Select Best Classifier & Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLamoiyIBYMG"
      },
      "source": [
        "## Step 1: Configuration & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRkV5j0-BYMG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "TRAIN_PATH = r\"C:\\Users\\Michael\\Desktop\\Research Capstone\"\n",
        "CLASSES = ['Lake', 'Desert', 'Mountain']\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 40\n",
        "LEARNING_RATE = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLoA_vUnBYMH"
      },
      "source": [
        "## Step 2: Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVhXZy7xBYMH"
      },
      "outputs": [],
      "source": [
        "print(\"--- Loading & Resizing Images ---\")\n",
        "\n",
        "X_train_list, y_train_list = [], []\n",
        "X_test_list, y_test_list = [], []\n",
        "\n",
        "for label_id, label_name in enumerate(CLASSES):\n",
        "    folder_path = os.path.join(TRAIN_PATH, label_name)\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: {folder_path} not found.\")\n",
        "        continue\n",
        "\n",
        "    image_files = os.listdir(folder_path)[:1200]\n",
        "    print(f\"Processing {label_name}: {len(image_files)} images.\")\n",
        "\n",
        "    class_imgs = []\n",
        "    for file in image_files:\n",
        "        try:\n",
        "            img_path = os.path.join(folder_path, file)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "                class_imgs.append(img)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    class_imgs = np.array(class_imgs)\n",
        "\n",
        "    X_train_list.extend(class_imgs[:800])\n",
        "    y_train_list.extend([label_id] * 800)\n",
        "    X_test_list.extend(class_imgs[800:920])\n",
        "    y_test_list.extend([label_id] * 120)\n",
        "\n",
        "X_train = np.array(X_train_list).astype('float32') / 255.0\n",
        "y_train = np.array(y_train_list)\n",
        "X_test = np.array(X_test_list).astype('float32') / 255.0\n",
        "y_test = np.array(y_test_list)\n",
        "\n",
        "print(f\"Data Ready: Train {X_train.shape}, Test {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqOnOAiBYMI"
      },
      "source": [
        "## Step 3: Train DenseNet Models & Select Top 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dEQFlpYBYMI"
      },
      "outputs": [],
      "source": [
        "densenet_variants = {\n",
        "    'DenseNet121': DenseNet121,\n",
        "    'DenseNet169': DenseNet169,\n",
        "    'DenseNet201': DenseNet201\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "model_accuracies = {}\n",
        "model_histories = {}   # <--- new dict to store histories\n",
        "\n",
        "for model_name, model_func in densenet_variants.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    K.clear_session()\n",
        "    base_model = model_func(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    predictions = Dense(3, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=SGD(learning_rate=LEARNING_RATE, momentum=0.9),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(X_test, y_test)\n",
        "    )\n",
        "    loss, acc = model.evaluate(X_test, y_test)\n",
        "    trained_models[model_name] = model\n",
        "    model_accuracies[model_name] = acc\n",
        "    model.save(f\"{model_name}.h5\")\n",
        "    with open(f\"{model_name}_history.json\", \"w\") as f:\n",
        "        json.dump(history.history, f)\n",
        "\n",
        "sorted_models = sorted(model_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
        "best_name_1, best_name_2 = sorted_models[0][0], sorted_models[1][0]\n",
        "model_A, model_B = trained_models[best_name_1], trained_models[best_name_2]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unBZFH6JBYMI"
      },
      "source": [
        "## Training Loss and Validation Graph DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe4e6CGNBYMJ"
      },
      "outputs": [],
      "source": [
        "# Training loss and validation loss graph (SMOOTH)\n",
        "\n",
        "epochs = range(len(history.history['loss']))\n",
        "\n",
        "\n",
        "plt.plot(epochs, history.history['loss'],\n",
        "         color='gold', linewidth=2, label='Training Loss')\n",
        "\n",
        "plt.plot(epochs, history.history['val_loss'],\n",
        "         color='green', linewidth=2, label='Validation Loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.grid(False)\n",
        "\n",
        "plt.savefig(\"Loss_Smooth.tiff\", format=\"tiff\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8bTleurBYMJ"
      },
      "source": [
        "## Training Accuracy and Validation Accuracy Graph DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh54xWvTBYMJ"
      },
      "outputs": [],
      "source": [
        "# Training accuracy and validation accuracy graph (SMOOTH)\n",
        "\n",
        "epochs = range(len(history.history['accuracy']))\n",
        "\n",
        "plt.plot(epochs, history.history['accuracy'],\n",
        "         color='gold', linewidth=2, label='Training Accuracy')\n",
        "\n",
        "plt.plot(epochs, history.history['val_accuracy'],\n",
        "         color='green', linewidth=2, label='Validation Accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.grid(False)  # clean look with no grid lines\n",
        "\n",
        "plt.savefig(\"Accuracy_Smooth.tiff\", format=\"tiff\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UXakPW_BYMJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# use the best model (from your sorted_models)\n",
        "best_model = model_A        # this is what you already defined\n",
        "# or: best_model = trained_models[best_name_1]\n",
        "\n",
        "# predicted probabilities on test set\n",
        "y_prob = best_model.predict(X_test)\n",
        "\n",
        "# convert to class indices (0, 1, 2)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZq0ut8kBYMJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of best model: {:.3f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJwOPkMbBYMJ"
      },
      "outputs": [],
      "source": [
        "print(\"Best model:\", best_name_1)\n",
        "print(\"Best model:\", best_name_2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpzdpXwNBYMJ"
      },
      "source": [
        "## DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWKo9NXdBYMK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "f = sns.heatmap(cm, annot=True, fmt='d', cmap=\"hot\")\n",
        "\n",
        "f.set_xlabel('Predicted label')\n",
        "f.set_ylabel('True label')\n",
        "\n",
        "f.xaxis.set_ticklabels(['Desert', 'Mountain', 'Lake'])\n",
        "f.yaxis.set_ticklabels(['Desert', 'Mountain', 'Lake'])\n",
        "\n",
        "plt.savefig(\"CM.tiff\", format=\"tiff\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UehDh83-BYMK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Use DenseNet121 ONLY\n",
        "dn121_model = trained_models[\"DenseNet121\"]\n",
        "\n",
        "# number of classes\n",
        "classes = [0, 1, 2]\n",
        "\n",
        "# predicted probabilities from DN121\n",
        "y_prob = dn121_model.predict(X_test)\n",
        "\n",
        "# binarize true labels\n",
        "y_test_bin = label_binarize(y_test, classes=classes)\n",
        "\n",
        "# compute micro-average ROC\n",
        "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_prob.ravel())\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC (DenseNet121): {roc_auc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-ToXGxKBYMK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "plt.plot(fpr, tpr, label=f\"DenseNet121 ROC (AUC = {roc_auc:.2f})\", linewidth=2)\n",
        "\n",
        "# Diagonal baseline\n",
        "plt.plot([0, 1], [0, 1], 'y--', linewidth=1)\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Save\n",
        "plt.savefig(\"ROC_DN121.tiff\", format=\"tiff\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ-w38NBBYMK"
      },
      "source": [
        "## Convolutional Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPae_Mu9BYMK"
      },
      "outputs": [],
      "source": [
        "best_model = model_A      # BEST model chosen by accuracy\n",
        "img = X_test[0:1]         # any test image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0PleXeQBYMK"
      },
      "outputs": [],
      "source": [
        "###### CL1 Feature Maps\n",
        "M_CL1 = Model(inputs=best_model.inputs, outputs=best_model.layers[2].output)\n",
        "feature_maps = M_CL1.predict(img)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "square=5\n",
        "ix=1\n",
        "ax=pyplot.figure(figsize=(5,5))\n",
        "\n",
        "for i in range(square):\n",
        "    for j in range(square):\n",
        "        ax = pyplot.subplot(square, square, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_aspect('equal')\n",
        "        pyplot.imshow(feature_maps[0, :, :, ix-1], aspect='auto', cmap=\"hot\")\n",
        "        ix += 1\n",
        "\n",
        "pyplot.savefig(\"CL1.tiff\", format=\"tiff\")\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-k0y3fTBYMK"
      },
      "outputs": [],
      "source": [
        "###### CL2 Feature Maps\n",
        "M_CL2 = Model(inputs=best_model.inputs, outputs=best_model.layers[8].output)\n",
        "feature_maps = M_CL2.predict(img)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "square=5\n",
        "ix=1\n",
        "ax=pyplot.figure(figsize=(5,5))\n",
        "\n",
        "for i in range(square):\n",
        "    for j in range(square):\n",
        "        ax = pyplot.subplot(square, square, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_aspect('equal')\n",
        "        pyplot.imshow(feature_maps[0, :, :, ix-1], aspect='auto', cmap=\"hot\")\n",
        "        ix += 1\n",
        "\n",
        "pyplot.savefig(\"CL2.tiff\", format=\"tiff\")\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2B6bC4zIBYMK"
      },
      "outputs": [],
      "source": [
        "###### CL3 Feature Maps\n",
        "M_CL3 = Model(inputs=best_model.inputs, outputs=best_model.layers[15].output)\n",
        "feature_maps = M_CL3.predict(img)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "square=5\n",
        "ix=1\n",
        "ax=pyplot.figure(figsize=(5,5))\n",
        "\n",
        "for i in range(square):\n",
        "    for j in range(square):\n",
        "        ax = pyplot.subplot(square, square, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_aspect('equal')\n",
        "        pyplot.imshow(feature_maps[0, :, :, ix-1], aspect='auto', cmap=\"hot\")\n",
        "        ix += 1\n",
        "\n",
        "pyplot.savefig(\"CL3.tiff\", format=\"tiff\")\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpbluFuHBYML"
      },
      "outputs": [],
      "source": [
        "###### CL4 Feature Maps\n",
        "M_CL4 = Model(inputs=best_model.inputs, outputs=best_model.layers[25].output)\n",
        "feature_maps = M_CL4.predict(img)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "square=5\n",
        "ix=1\n",
        "ax=pyplot.figure(figsize=(5,5))\n",
        "\n",
        "for i in range(square):\n",
        "    for j in range(square):\n",
        "        ax = pyplot.subplot(square, square, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_aspect('equal')\n",
        "        pyplot.imshow(feature_maps[0, :, :, ix-1], aspect='auto', cmap=\"hot\")\n",
        "        ix += 1\n",
        "\n",
        "pyplot.savefig(\"CL4.tiff\", format=\"tiff\")\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMaUWHisBYML"
      },
      "source": [
        "## Step 4: Feature Fusion Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0ptQLNMBYML"
      },
      "outputs": [],
      "source": [
        "extractor_A = Model(inputs=model_A.input, outputs=model_A.layers[-2].output)\n",
        "extractor_B = Model(inputs=model_B.input, outputs=model_B.layers[-2].output)\n",
        "\n",
        "input_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "feat_a = extractor_A(input_img)\n",
        "feat_b = extractor_B(input_img)\n",
        "reduced_a = Dense(500, activation='relu')(feat_a)\n",
        "reduced_b = Dense(500, activation='relu')(feat_b)\n",
        "fused_vector = Concatenate()([reduced_a, reduced_b])\n",
        "fused_model = Model(inputs=input_img, outputs=fused_vector)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVn2yTqeBYML"
      },
      "source": [
        "## Step 5: Generate Fused Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QtuzfBsBYML"
      },
      "outputs": [],
      "source": [
        "X_train_FFV = fused_model.predict(X_train)\n",
        "X_test_FFV = fused_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn_mS-9YBYML"
      },
      "source": [
        "## Step 6: Classical Classification & Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQQl44TyBYML"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "    'SoftMax (Logistic Regression)': LogisticRegression(max_iter=1000, multi_class='multinomial'),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100)\n",
        "}\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    scores = cross_val_score(clf, X_train_FFV, y_train, cv=kfold)\n",
        "    results[name] = scores.mean()\n",
        "\n",
        "best_clf_name = max(results, key=results.get)\n",
        "best_clf = classifiers[best_clf_name]\n",
        "best_clf.fit(X_train_FFV, y_train)\n",
        "pred = best_clf.predict(X_test_FFV)\n",
        "print(classification_report(y_test, pred, target_names=CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5H_ITWMBYMM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def compute_metrics(y_true, y_pred, num_classes=3):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
        "\n",
        "    # per-class TP,FN,TN,FP (one-vs-rest)\n",
        "    TP_list = []\n",
        "    FN_list = []\n",
        "    TN_list = []\n",
        "    FP_list = []\n",
        "\n",
        "    for c in range(num_classes):\n",
        "        TP = cm[c,c]\n",
        "        FN = cm[c,:].sum() - TP\n",
        "        FP = cm[:,c].sum() - TP\n",
        "        TN = cm.sum() - (TP + FN + FP)\n",
        "\n",
        "        TP_list.append(TP)\n",
        "        FN_list.append(FN)\n",
        "        TN_list.append(TN)\n",
        "        FP_list.append(FP)\n",
        "\n",
        "    # macro-average like article\n",
        "    TP_macro = np.mean(TP_list)\n",
        "    FN_macro = np.mean(FN_list)\n",
        "    TN_macro = np.mean(TN_list)\n",
        "    FP_macro = np.mean(FP_list)\n",
        "\n",
        "    AC = (TP_macro + TN_macro) / (TP_macro + TN_macro + FP_macro + FN_macro)\n",
        "    PR = TP_macro / (TP_macro + FP_macro)\n",
        "    SE = TP_macro / (TP_macro + FN_macro)\n",
        "    SP = TN_macro / (TN_macro + FP_macro)\n",
        "\n",
        "    return TP_macro, FN_macro, TN_macro, FP_macro, AC, PR, SE, SP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I6PA5t6BYMM"
      },
      "outputs": [],
      "source": [
        "dn_results = {}\n",
        "\n",
        "for name in [\"DenseNet121\", \"DenseNet169\", \"DenseNet201\"]:\n",
        "    print(f\"Evaluating {name}...\")\n",
        "\n",
        "    model = trained_models[name]\n",
        "\n",
        "    y_prob = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "    TP, FN, TN, FP, AC, PR, SE, SP = compute_metrics(y_test, y_pred)\n",
        "\n",
        "    dn_results[name] = [TP, FN, TN, FP, AC*100, PR*100, SE*100, SP*100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-dM7505BYMM"
      },
      "outputs": [],
      "source": [
        "fusion_results = {}\n",
        "\n",
        "fusion_models = {\n",
        "    \"FFV-SM\": classifiers['SoftMax (Logistic Regression)'],\n",
        "    \"FFV-DT\": classifiers['Decision Tree'],\n",
        "    \"FFV-RF\": classifiers['Random Forest']\n",
        "}\n",
        "\n",
        "for name, clf in fusion_models.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "\n",
        "    clf.fit(X_train_FFV, y_train)\n",
        "    pred = clf.predict(X_test_FFV)\n",
        "\n",
        "    TP, FN, TN, FP, AC, PR, SE, SP = compute_metrics(y_test, pred)\n",
        "\n",
        "    fusion_results[name] = [TP, FN, TN, FP, AC*100, PR*100, SE*100, SP*100]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYNKpX_ABYMM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "\n",
        "# DenseNets\n",
        "for name, vals in dn_results.items():\n",
        "    rows.append([name] + list(np.round(vals, 4)))\n",
        "\n",
        "# Fusion models\n",
        "for name, vals in fusion_results.items():\n",
        "    rows.append([name] + list(np.round(vals, 4)))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Model\", \"TP\", \"FN\", \"TN\", \"FP\", \"AC\", \"PR\", \"SE\", \"SP\"\n",
        "])\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCDZwDSkBYMM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---- Convert your existing df into an image ----\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "\n",
        "ax.axis('off')   # Hide axis\n",
        "\n",
        "table = ax.table(\n",
        "    cellText=df.values,\n",
        "    colLabels=df.columns,\n",
        "    loc='center',\n",
        "    cellLoc='center'\n",
        ")\n",
        "\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1.2, 1.2)\n",
        "\n",
        "plt.savefig(\"Performance_Table.tiff\", dpi=300, format=\"tiff\", bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (sat_gpu)",
      "language": "python",
      "name": "sat_gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}